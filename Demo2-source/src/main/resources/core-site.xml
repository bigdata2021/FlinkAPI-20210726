<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>

<property>
<name>fs.defaultFS</name>
<value>hdfs://HdfsCluster</value>
<description>把两个NameNode的地址组装成一个集群HdfsCluster</description>
</property>

<property>
<name>hadoop.tmp.dir</name>
<value>/opt/module/hadoop-3.1.4/metaData</value>
<description>指定hadoop运行时产生文件的存储目录，默认路径存在被删除的可能，要求要么不存在，要么是空路径</description>
</property>

<property>
<name>ha.zookeeper.quorum</name>
<value>node1:2181,node2:2181,node3:2181</value>
<description>指定zk(RPC)地址</description>
</property>

<property>
<name>hadoop.proxyuser.bigdata.hosts</name>
<value>*</value>
<description>hadoop与hive兼容性设置：
Hadoop2.0版本开始支持ProxyUser的机制。含义是使用User A的用户认证信息，以User B的名义去访问hadoop集群。对于服务端来说就认为此时是User B在访问集群，相应对访问请求的鉴权（包括HDFS文件系统的权限，YARN提交任务队列的权限）都以用户User B来进行。User A被认为是superuser（这里super user并不等同于hdfs中的超级用户，只是拥有代理某些用户的权限，对于hdfs来说本身也是普通用户），User B被认为是proxyuser。
</description>
</property>

<property>
<name>hadoop.proxyuser.bigdata.groups</name>
<value>*</value>
</property>

<property>
<name>hadoop.http.staticuser.user</name>
<value>bigdata</value>
<description>修改HDFS,YARN默认操作用户为bigdata(默认用户为dr.who)</description>
</property>

<property>
<name>io.compression.codecs</name>
<value>
org.apache.hadoop.io.compress.GzipCodec,
org.apache.hadoop.io.compress.DefaultCodec,
org.apache.hadoop.io.compress.BZip2Codec,
org.apache.hadoop.io.compress.SnappyCodec,
com.hadoop.compression.lzo.LzoCodec,
com.hadoop.compression.lzo.LzopCodec
</value>
</property>

<property>
<name>io.compression.codec.lzo.class</name>
<value>com.hadoop.compression.lzo.LzoCodec</value>
</property>

</configuration>
